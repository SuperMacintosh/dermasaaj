{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57fb832b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b0781b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-14 15:27:08.880038: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-14 15:27:08.988359: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-14 15:27:08.992303: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-06-14 15:27:08.992315: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-06-14 15:27:09.018608: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-06-14 15:27:09.611545: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-14 15:27:09.611645: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-14 15:27:09.611651: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import dermaflow.logic.preprocessing as pr\n",
    "from dermaflow.params import *\n",
    "from keras import Model, Sequential, layers\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "from dermaflow.logic.preprocessing import data_augmentation\n",
    "import dermaflow.logic.model as md"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9638f34",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0de9b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#url_file_name=\"https://storage.googleapis.com/derma-data/raw_data/archive.zip\"\n",
    "#parent_path=pr.initialize_dataset_from_file(url_file_name,extract=True,archive_format='zip')\n",
    "parent_path='../../../.keras/datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b03c21ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b68b3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_image_data(parent_path, child_path, img_height:int, img_width:int,batch_size:int=os.getenv('BATCH_SIZE') ):\n",
    "    \"\"\"\n",
    "    get from targeted tensor path and return all existing files\n",
    "    \"\"\"\n",
    "    path=os.path.join(parent_path + f'/{child_path}')\n",
    "    bloc = tf.keras.utils.image_dataset_from_directory(\n",
    "    path,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "    return bloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ab6e305",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height=IMAGE_HEIGHT\n",
    "img_width=IMAGE_WIDTH\n",
    "batch_size=BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ae0d12a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20179 files belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "bloc = tf.keras.utils.image_dataset_from_directory('/home/salah/.keras/datasets/data/train', image_size=(img_height, img_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d2df09",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.load_img()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b392cd4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/salah/code/SuperMacintosh/dermasaaj/Untitled1.ipynb Cell 10\u001b[0m in \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/salah/code/SuperMacintosh/dermasaaj/Untitled1.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m child_path\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdata/train\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/salah/code/SuperMacintosh/dermasaaj/Untitled1.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m train_ds\u001b[39m=\u001b[39mpr\u001b[39m.\u001b[39mget_split_image_data(parent_path, child_path, img_height, img_width,batch_size )\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/salah/code/SuperMacintosh/dermasaaj/Untitled1.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m child_path\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdata/test\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/salah/code/SuperMacintosh/dermasaaj/Untitled1.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m test_ds\u001b[39m=\u001b[39mpr\u001b[39m.\u001b[39mget_split_image_data(parent_path, child_path, img_height, img_width,batch_size )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pr' is not defined"
     ]
    }
   ],
   "source": [
    "child_path='data/train'\n",
    "train_ds=pr.get_split_image_data(parent_path, child_path, img_height, img_width,batch_size )\n",
    "child_path='data/test'\n",
    "test_ds=pr.get_split_image_data(parent_path, child_path, img_height, img_width,batch_size )\n",
    "child_path='data/valid'\n",
    "val_ds=pr.get_split_image_data(parent_path, child_path, img_height, img_width,batch_size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b362fae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "✅ Model initialized\n"
     ]
    }
   ],
   "source": [
    "num_classes=len(train_ds.class_names)\n",
    "kernel_size=3\n",
    "val_dropout=0.2\n",
    "model=md.initialize_model(num_classes, kernel_size, val_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1700cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model compiled\n"
     ]
    }
   ],
   "source": [
    "model=md.compile_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6fbc102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/salah/.pyenv/versions/3.10.6/envs/dermasaaj/lib/python3.10/site-packages/keras/backend.py:5582: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "1262/1262 [==============================] - 278s 218ms/step - loss: 1.4978 - accuracy: 0.5253 - val_loss: 1.2869 - val_accuracy: 0.5511\n",
      "Epoch 2/20\n",
      "1262/1262 [==============================] - 245s 194ms/step - loss: 1.2530 - accuracy: 0.5463 - val_loss: 1.2757 - val_accuracy: 0.5318\n",
      "Epoch 3/20\n",
      "1262/1262 [==============================] - 233s 184ms/step - loss: 1.2380 - accuracy: 0.5481 - val_loss: 1.2317 - val_accuracy: 0.5389\n",
      "Epoch 4/20\n",
      "1262/1262 [==============================] - 233s 184ms/step - loss: 1.2131 - accuracy: 0.5524 - val_loss: 1.2108 - val_accuracy: 0.5570\n",
      "Epoch 5/20\n",
      "1262/1262 [==============================] - 266s 210ms/step - loss: 1.1933 - accuracy: 0.5625 - val_loss: 1.1958 - val_accuracy: 0.5640\n",
      "Epoch 6/20\n",
      "1262/1262 [==============================] - 234s 185ms/step - loss: 1.1851 - accuracy: 0.5622 - val_loss: 1.1936 - val_accuracy: 0.5617\n",
      "Epoch 7/20\n",
      "1262/1262 [==============================] - 231s 183ms/step - loss: 1.1762 - accuracy: 0.5648 - val_loss: 1.1700 - val_accuracy: 0.5660\n",
      "Epoch 8/20\n",
      "1262/1262 [==============================] - 223s 177ms/step - loss: 1.1620 - accuracy: 0.5703 - val_loss: 1.1698 - val_accuracy: 0.5687\n",
      "Epoch 9/20\n",
      "1262/1262 [==============================] - 257s 203ms/step - loss: 1.1585 - accuracy: 0.5730 - val_loss: 1.1621 - val_accuracy: 0.5734\n",
      "Epoch 10/20\n",
      "1262/1262 [==============================] - 258s 204ms/step - loss: 1.1519 - accuracy: 0.5754 - val_loss: 1.1849 - val_accuracy: 0.5601\n",
      "Epoch 11/20\n",
      "1262/1262 [==============================] - ETA: 0s - loss: 1.1495 - accuracy: 0.5738Restoring model weights from the end of the best epoch: 9.\n",
      "1262/1262 [==============================] - 245s 194ms/step - loss: 1.1495 - accuracy: 0.5738 - val_loss: 1.1666 - val_accuracy: 0.5809\n",
      "Epoch 11: early stopping\n",
      "✅ Model succesfully trained through 11 epochs\n"
     ]
    }
   ],
   "source": [
    "patience=2\n",
    "verbose=1\n",
    "model, history=md.train_model(\n",
    "        model,\n",
    "        train_ds,\n",
    "        val_ds,\n",
    "        batch_size=batch_size,\n",
    "        patience=patience,\n",
    "        verbose=verbose\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e610452",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'md' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/salah/code/SuperMacintosh/dermasaaj/Untitled1.ipynb Cell 13\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/salah/code/SuperMacintosh/dermasaaj/Untitled1.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m test\u001b[39m=\u001b[39mmd\u001b[39m.\u001b[39mevaluate_model(\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/salah/code/SuperMacintosh/dermasaaj/Untitled1.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m         model2,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/salah/code/SuperMacintosh/dermasaaj/Untitled1.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m         test_ds,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/salah/code/SuperMacintosh/dermasaaj/Untitled1.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m         batch_size\u001b[39m=\u001b[39mBATCH_SIZE\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/salah/code/SuperMacintosh/dermasaaj/Untitled1.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m         )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'md' is not defined"
     ]
    }
   ],
   "source": [
    "test=md.evaluate_model(\n",
    "        model2,\n",
    "        test_ds,\n",
    "        batch_size=BATCH_SIZE\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d3fb90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-08 16:20:31.437316: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-08 16:20:31.860326: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-08 16:20:32.071279: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-06-08 16:20:32.071315: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-06-08 16:20:32.143109: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-06-08 16:20:33.701612: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-08 16:20:33.702078: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-08 16:20:33.702086: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import dermaflow.logic.registry as rg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a204fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved locally\n"
     ]
    }
   ],
   "source": [
    "rg.save_model(model) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "409b18ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 1.0466341972351074, 'accuracy': 0.6193400025367737}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b2c215d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local\n",
      "\n",
      "Load latest model from local registry...\n",
      "\n",
      "Load latest model from disk...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-08 16:20:41.689589: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-06-08 16:20:41.690277: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-06-08 16:20:41.690345: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (PCSalah): /proc/driver/nvidia/version does not exist\n",
      "2023-06-08 16:20:41.701582: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "✅ Model loaded from local disk\n"
     ]
    }
   ],
   "source": [
    "model2=rg.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3472907",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dermaflow.params import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3efe84b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "06aeb509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "❌ No model found where asked\n"
     ]
    }
   ],
   "source": [
    "model2=rg.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "97954e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b00a75ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/salah/.pyenv/versions/3.10.6/envs/dermasaaj/lib/python3.10/site-packages/keras/backend.py:5582: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model evaluated, [Loss, Accuracy]: [1.18,0.57]\n"
     ]
    }
   ],
   "source": [
    "test=md.evaluate_model(\n",
    "        model2,\n",
    "        test_ds,\n",
    "        batch_size=BATCH_SIZE\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "242f60eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from dermaflow.params import *\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69b81ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "! direnv allow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bae98829",
   "metadata": {},
   "outputs": [],
   "source": [
    "! direnv reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29fdb1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dermaflow.params import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07caf216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DenseNet121'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cd096bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/salah/.lewagon/mlops/project_outputs', 'DenseNet121', 'keras')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOCAL_REGISTRY_PATH, MODEL_TYPE, MODEL_SUFFIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccfead7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/salah/.lewagon/mlops/project_outputs/models\n",
      "['/home/salah/.lewagon/mlops/project_outputs/models/DenseNet121_best_model.keras']\n",
      "/home/salah/.lewagon/mlops/project_outputs/models/DenseNet121_best_model.keras\n",
      "\n",
      "Load latest model from disk...\n",
      "✅ Model compiled\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from dermaflow.params import *\n",
    "from dermaflow.logic.model import compile_model\n",
    "\n",
    "\n",
    "local_model_directory = os.path.join(LOCAL_REGISTRY_PATH, \"models\")\n",
    "print(local_model_directory)\n",
    "local_model_paths = glob.glob(f\"{local_model_directory}/{MODEL_TYPE}_*.{MODEL_SUFFIX}\")\n",
    "print(local_model_paths)\n",
    "if not local_model_paths:\n",
    "    print(f\"\\n❌ repo not found {local_model_paths}\")\n",
    "            \n",
    "\n",
    "most_recent_model_path_on_disk = sorted(local_model_paths)[-1]\n",
    "print(most_recent_model_path_on_disk)\n",
    "print(\"\\nLoad latest model from disk...\")\n",
    "\n",
    "latest_model = keras.models.load_model(most_recent_model_path_on_disk, compile=False)\n",
    "latest_model = compile_model (latest_model, MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bae9b032",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dermaflow.logic.registry import load_model, compile_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00f1d552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Load latest model from local registry...\n",
      "/home/salah/.lewagon/mlops/project_outputs/models\n",
      "/home/salah/.lewagon/mlops/project_outputs/models/DenseNet121_best_model.keras\n",
      "\n",
      "Load latest model from disk...\n",
      "✅ Model loaded from local disk\n"
     ]
    }
   ],
   "source": [
    "latest_model =load_model(compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6913f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_model=latest_model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy', tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bbaf2f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_HEIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd9739c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "! direnv reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0e32b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.densenet import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "114bbb22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 150)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_HEIGHT, IMAGE_WIDTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3cb01ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "img = tf.keras.utils.load_img('ISIC_0000395_downsampled.jpg', target_size=(IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = preprocess_input(img_array)    #preprocess input DenseNet\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "# model =load_model(compile=False)\n",
    "model=keras.models.load_model('/home/salah/.lewagon/mlops/project_outputs/models/DenseNet121_best_model.keras', compile=False)\n",
    "# model = compile_model(model, MODEL_TYPE)\n",
    "#model.compile(optimizer='adam',\n",
    "              #loss='categorical_crossentropy',\n",
    "              #metrics=['accuracy', tf.keras.metrics.Recall()])\n",
    "predictions = model.predict(img_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a8ca5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.8603612e-04, 1.4716612e-04, 1.6977508e-01, 3.7745427e-05,\n",
       "        7.2178942e-01, 1.0715708e-01, 9.0602547e-04, 1.4202693e-06]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72bc49e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[1.8603612e-04 1.4716612e-04 1.6977508e-01 3.7745427e-05 7.2178942e-01\\n 1.0715708e-01 9.0602547e-04 1.4202693e-06]']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[str(x) for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ded4542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[1.8603612e-04 1.4716612e-04 1.6977508e-01 3.7745427e-05 7.2178942e-01\\n 1.0715708e-01 9.0602547e-04 1.4202693e-06]'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'-'.join(str(x) for x in predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a2cadc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
